{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvRjrs1Pis8YAfYSmrAykX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helghand1/MAT421/blob/main/Medical_Calculation_Verification_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hussein ElGhandour\n",
        "\n",
        "## MAT 421 Project Plan\n",
        "\n",
        "### Medical Calculation Verification Agent"
      ],
      "metadata": {
        "id": "NYytCbFhZmhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introduction to the Problem**\n",
        "\n",
        "In healthcare settings, accurate medical calculations are critical for ensuring patient safety and effective treatment. Clinicians frequently rely on precise formulas to determine essential metrics such as Body Mass Index (BMI), Body Surface Area (BSA), and medication dosages. Errors in these calculations can lead to serious consequences, including incorrect medication administration or misjudged treatment plans.\n",
        "\n",
        "Despite the importance of accuracy, medical professionals often face challenges such as time pressure, complex multi-variable formulas, and the need to cross-reference medical guidelines. Developing a tool that leverages Large Language Models (LLMs) to verify medical calculations can significantly reduce errors and improve clinical efficiency.\n",
        "\n",
        "To address this issue, this project aims to create a Medical Calculation Verification Agent that uses an LLM to review and validate common medical calculations. By enabling healthcare providers to quickly confirm their results, this tool can help reduce mistakes and improve decision-making. The project will apply core mathematical concepts like arithmetic operations, unit conversions, and error analysis, all while demonstrating practical Python programming skills."
      ],
      "metadata": {
        "id": "mFiAb02FZxor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Related Work**\n",
        "\n",
        "Traditional clinical calculators, such as MedCalc and MDCalc, are widely used by healthcare professionals to perform various medical calculations. While these tools provide quick access to numerous clinical decision-support instruments, they often function as static calculators without dynamic error-checking or contextual explanations. This limitation can lead to potential errors if the input data is incorrect or if the clinician misinterprets the results.​\n",
        "\n",
        "Recent advancements in artificial intelligence, particularly Large Language Models (LLMs) like OpenAI's GPT-4, have opened new avenues for enhancing medical tools. Studies have demonstrated that GPT-4 can pass medical licensing examinations, indicating its potential to assist in clinical decision-making by processing and generating human-like text. For instance, GPT-4 \"can achieve an overall accuracy rate of 81% across medical licensing exams from different countries, successfully passing most of these exams\" (Liu et al., 2024a). This capability allows LLMs to provide detailed explanations and context for medical calculations, potentially reducing errors and improving understanding.\n",
        "\n",
        "However, integrating LLMs into healthcare applications presents challenges, including ensuring accuracy, maintaining patient privacy, and obtaining regulatory approval. Despite these challenges, the potential benefits of LLMs in providing dynamic, context-aware medical calculations make them a promising area for further research and development (Liu et al., 2024b).\n",
        "\n",
        "While existing clinical calculators provide valuable decision-support tools, they often lack dynamic error-checking and clear explanations for results. Similarly, while LLMs have shown strong potential in medical reasoning, their integration into medical calculation verification remains underexplored. This project aims to bridge that gap by developing an LLM-based Medical Calculation Verification Agent that not only verifies calculations but also offers contextual explanations to reduce errors and improve clinical decision-making."
      ],
      "metadata": {
        "id": "d-yF8BMIhGu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Proposed Methodology/Models**\n",
        "\n",
        "The proposed system will utilize a Large Language Model (LLM), such as OpenAI's GPT or DeepSeek API, to build a Medical Calculation Verification Agent. The agent will verify key medical calculations through structured prompts designed to guide the model in performing arithmetic checks, unit conversions, and error analysis.\n",
        "\n",
        "The implementation will be developed using Python in Google Colab to ensure accessibility and ease of sharing. The agent will query the LLM via API calls, leveraging either the OpenAI's GPT model. To enhance calculation accuracy, libraries such as NumPy and SymPy will be employed for precise mathematical validation, while Pandas will manage data inputs and outputs in tabular form to improve usability for healthcare professionals.\n",
        "\n",
        "Key techniques will include prompt engineering to ensure the LLM follows a structured format when verifying calculations. The prompts will define clear input instructions, calculation steps, and result expectations. The system will also incorporate a dedicated validation process, where the LLM's output is compared against trusted medical references (e.g., Mayo Clinic guidelines), flagging discrepancies and providing meaningful feedback. Finally, the system will integrate error analysis techniques, including rounding precision checks and tolerance thresholds, to improve the agent's ability to detect and manage minor calculation errors in a medical context."
      ],
      "metadata": {
        "id": "jDASl3NujUjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment Setups**\n",
        "\n",
        "The evaluation of the Medical Calculation Verification Agent will involve testing the system's accuracy, reliability, and efficiency across multiple medical calculation scenarios. Data for these tests will be sourced from publicly available medical datasets, such as those found on platforms like Kaggle or PhysioNet. Specifically, datasets containing patient information and clinical measurements (e.g., BMI values, medication dosages, and vital signs) will be used to provide real-world data points for evaluation.\n",
        "\n",
        "The data collection process will involve extracting relevant features from these datasets, such as patient weight, height, age, and prescribed medication details. This structured data will be formatted into tabular input that mimics the information a healthcare provider would enter in practice. Additionally, synthetic data will be generated to simulate edge cases and challenging scenarios, such as borderline BMI values or extreme medication dosages, ensuring the model can handle a wide range of inputs.\n",
        "\n",
        "Data for these tests will be sourced from publicly available medical datasets, such as the MIMIC-IV v3.1 (Johnson et al., 2024) dataset from PhysioNet and the Personalized Medication Dataset (Ziya, 2025) from Kaggle. Specifically, MIMIC-IV contains patient information and clinical measurements (e.g., BMI values, medication dosages, and vital signs), providing real-world data points for evaluation. Similarly, the Personalized Medication Dataset includes patient profiles and treatment plans, which are instrumental in assessing personalized medication dosages and related calculations.​\n",
        "\n",
        "For analysis, the LLM's verification outputs will be compared against ground-truth values calculated using established medical formulas. Key metrics for evaluation will include accuracy, measured by the percentage of correct verifications relative to the ground-truth values, and error rate, which will assess discrepancies in calculated values with tolerance thresholds defined for acceptable variance. Additionally, response time will be tracked to evaluate the speed of the LLM’s calculations and assess its practicality in clinical settings.\n",
        "\n",
        "To further validate the model's reliability, multiple test cases will be conducted for each calculation type, ensuring consistency across diverse scenarios. Statistical analysis tools such as SciPy and statsmodels will be employed to evaluate performance metrics and ensure robust, data-driven conclusions."
      ],
      "metadata": {
        "id": "kwr2KzPZltjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Expected Results**\n",
        "\n",
        "The hypothesized outcome of this project is a Medical Calculation Verification Agent that accurately verifies key medical calculations, such as BMI, medication dosages, and Body Surface Area. The system is anticipated to achieve a high accuracy rate, ideally exceeding 95%, by ensuring precise calculation steps and identifying potential errors in medical formulas. Additionally, the agent is expected to provide meaningful feedback when discrepancies arise, helping healthcare professionals identify mistakes quickly and improve decision-making.\n",
        "\n",
        "The agent is also expected to demonstrate reliable performance across a range of medical scenarios, including edge cases involving extreme values or unusual data inputs. The system’s error rate should remain low, with minimal variance between the model's output and established medical guidelines. Furthermore, the response time is expected to be efficient enough for practical use in clinical settings, ensuring minimal disruption to healthcare workflows.\n",
        "\n",
        "By achieving these outcomes, this project aims to provide a valuable tool that enhances the safety, accuracy, and efficiency of medical calculations in healthcare environments."
      ],
      "metadata": {
        "id": "6WPOy3PmhZ5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Team Roles and Responsibilities**\n",
        "\n",
        "I will be completing this project on my own. Thus, I will take on every role and am solely responsible for the entire project."
      ],
      "metadata": {
        "id": "2tni4RVAq85_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **References**\n",
        "\n",
        "Johnson, A., Bulgarelli, L., Pollard, T., Gow, B., Moody, B., Horng, S., Celi, L. A., & Mark, R. (2024, October 11). Mimic-IV. MIMIC-IV v3.1. https://physionet.org/content/mimiciv/3.1/\n",
        "\n",
        "Liu, M., Okuhara, T., Dai, Z., Huang, W., Okada, H., Furukawa, E., & Kiuchi, T. (2024a, July 9). Performance of advanced large language models (GPT-4O, GPT-4, gemini 1.5 pro, claude 3 opus) on Japanese Medical Licensing Examination: A comparative study. medRxiv. https://www.medrxiv.org/content/10.1101/2024.07.09.24310129v1.full\n",
        "\n",
        "Liu, M., Okuhara, T., Chang, X., Shirabe, R., Nishiie, Y., Okada, H., & Kiuchi, T. (2024b, July 25). Performance of chatgpt across different versions in medical licensing examinations worldwide: Systematic review and meta-analysis. Journal of medical Internet research. https://pmc.ncbi.nlm.nih.gov/articles/PMC11310649/\n",
        "\n",
        "Ziya. (2025, January 3). Personalized medication dataset. Kaggle. https://www.kaggle.com/datasets/ziya07/personalized-medication-dataset/data"
      ],
      "metadata": {
        "id": "0s5EEotGineR"
      }
    }
  ]
}